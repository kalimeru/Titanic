---
  title: 'Tipologia i cicle de vida de les dades: PRA2'
  author: "Autor: Adem Ait; Dani Ponce"
  date: "Juny 2022"
  output:
    pdf_document:
      highlight: zenburn
      toc: yes
    word_document: default
    html_document:
      highlight: default
      number_sections: yes
      theme: cosmo
      toc: yes
      toc_depth: 2
---
  
``` {r setup, include=FALSE}  
setwd("C:/Users/kalim/OneDrive/Desktop/uoc/Tipologia/PRA2")

# Libraries
if (!require('ggplot2')) install.packages('ggplot2'); library(ggplot2)
if (!require('tidyverse')) install.packages('tidyverse'); library(tidyverse)
if (!require('rpart')) install.packages('rpart'); library(rpart)
if (!require('caret')) install.packages('caret'); library(caret)
if (!require('lattice')) install.packages('lattice'); library(lattice)
if (!require('randomForest')) install.packages('randomForest'); library(randomForest)
if (!require('VIM')) install.packages('VIM'); library(VIM)
if (!require('car')) install.packages('car'); library(car)
if (!require('lmtest')) install.packages('lmtest'); library(lmtest)
if (!require('pROC')) install.packages('pROC'); library(pROC)
if (!require('arules')) install.packages('arules'); library(arules)
if (!require('vcd')) install.packages('vcd'); library(vcd)
```

# Elecció del dataset

Nosaltres hem escollit el dataset anomenat [Titanic](https://www.kaggle.com/c/titanic). Aquest dataset (com a mínim des del repositori de Kaggle del quan l'hem obtingut) es conforma per dos fitxers CSV, un destinat a l'entrenament i l'altre a l'avaluació d'un model de *machine learning*. En aquest dataset trobem els passatgers del naviu Titanic, amb diversos atributs per a cada passatger, incloent el camp Survived, que indica si va sobreviure o no. La finalitat de l'entrenament d'aquest dataset serà predir si un passatger sobreviurà o no. Per tal de netejar totes les dades de la mateixa manera, juntarem els dos arxius en una sola estructura i treballarem sobre ella. Notem que el fitxer de les dades d'avaluació conté un atribut menys (l'objectiu; *target*), per tant a la columna del *target* (`Survived`) ficarem NA's. 

``` {r}
set.seed(123)

train <- read.csv("data/train.csv", stringsAsFactors = F)
test <- read.csv("data/test.csv", stringsAsFactors = F)

train$data <- "train"
test$data <- "test"

test$Survived <- NA
titanic <- rbind(train,test)
```

## Descripció de les dades

Un cop carregades les dades anem a entendre que es vol aconseguir amb aquest dataset i com està compost.

Aquest dataset conté les dades sobre els passatgers del icònic transatlàntic que va enfonsar per un iceberg l'any 1912. L'objectiu del conjunt de dades és saber si donada la informació d'un passatger (edat, classe, sexe, etc.) es pot predir si sobreviurà (va sobreviure, per ser estrictament correctes) o no a l'enfonsament del Titànic.

Anem a fer una inspecció ràpida d'aquest dataset:
``` {r}
dim(titanic)

head(titanic, 3)

str(titanic)
```

Primer veiem que el nostre conjunt conté 1309 observacions amb 13 variables. Després podem veure una petita selecció de mostra de com és el dataset. Per acabar veiem els tipus de les variables del nostre conjunt de dades. Per tant, abans de començar amb el preprocessament de les dades, anem a crear un diccionari del conjunt de dades:

+ **PassengerId** (enter): identificador del passatger
+ **Survived** (enter)(*target*): si el passatger va sobreviure o no
+ **Pclass** (enter): classe en la que el passatger viatjava
+ **Name** (caràcter): Nom del passatger
+ **Sex** (caràcter): Sexe del passatger
+ **Age** (decimal): Edat del passatger
+ **Sibsp** (enter): Nombre de germans/esposes a bord del Titànic
+ **parch** (enter): Nombre de pares/fills a bord del Titànic
+ **Ticket** (caràcter): número del ticket
+ **Fare** (decimal): Preu del viatge
+ **Cabin** (caràcter): Número de camarot
+ **Embarked** (caràcter): Port d'embarcació: C = Cherbourg, Q = Queenstown, S = Southampton
+ **data** (caràcter): dades d'entrenament o d'avaluació

# Neteja de les dades

Un cop entenem que significa cada variable, anem a analitzar-les. Respecte els tipus de dades veiem que hi ha alguns tipus inusuals, com per exemple l'edat sigui decimal enlloc de tipus enter. Anem a analitzar aquesta variable:

``` {r}
sort(unique(titanic$Age))
```

Veiem que trobem decimals pel cas que el passatger sigui un nadó menor d'un any, o mig any per alguns adults, per tant tot sembla correcte.

## Dades perdudes

Anem a veure si hi ha valors nuls o buits a les nostres dades:

``` {r}
# NAs
colSums(is.na(titanic))
```

Veiem que hi ha valors nuls a les columnes `Survived`, `Age` i `Fare`. Respecte la columna `Survived` els valors nuls corresponen a les files que pertanyen a les dades d'avaluació, per tant no hem de fer res. En canvi en les altres dos columnes els valors nuls no són legítims i, per tant, aplicarem una imputació per aquestes instàncies utilitzant la mediana (és més robusta als outliers que no pas la mitjana).

```{r}
# Treat NAs with central approach (median)
titanic$Age[is.na(titanic$Age)] <- median(titanic$Age, na.rm = T)
titanic$Fare[is.na(titanic$Fare)] <- median(titanic$Fare, na.rm = T)
```

Ara anem a veure si hi ha instàncies amb valors buits.

```{r}
colSums(titanic=="", na.rm = T)
```

Veiem que les columnes `Cabin` i `Embarked` tenen valors buits. En quant a la cabina, els valors són legítims i indiquen que el passatger no disposa de cabina. Per tant, crearem una nova variable per detectar els passatgers que tenen cabina i els que no.

```{r}
titanic$hasCabin <- ifelse(titanic$Cabin != "", 1, 0)
titanic$hasCabin <- as.factor(titanic$hasCabin)
summary(titanic$hasCabin)
```

Veiem com les 1014 instàncies que tenien valors buits representes els passatgers sense cabina i, els 295 restants els passatger amb cabina.

Respecte a la columna `Embarked`, transformarem els valors buits a `NA` per posteriorment aplicar una imputació basada en l'algorisme KNN.

```{r}
index <- which(titanic$Embarked=="")
titanic[index,]$Embarked <- NA
titanic$Embarked <- kNN(titanic)$Embarked
titanic[index,]$Embarked
```
Veiem com a les dues files se'ls hi ha assignat el port de Southampton. La imputació per KNN s'ha fet per mostrar una altra manera d'imputar dades perdudes. Hi ha altres mètodes per tractar valors nuls, com eliminar les files que continguin valors nuls, eliminar columnes que continguin un alt índex de valors nuls, imputar els valors perduts aplicant una substitució estadística (mitjana, mediana, etc), o mètodes més complexes com inferències basades en la regressió, models bayesians o arbres de decisió.

## Discretització

Seguim amb el tractament de les dades factoritzant tres columnes d'especial interés (ens semblen columnes bastant relevants, o en el cas d'`Embarked` té pocs valors únics per tant és bona idea factoritzar).

```{r}
col_factors <- c("Survived", "Sex", "Embarked")
titanic[,col_factors] <- lapply(titanic[,col_factors], as.factor)
summary(titanic[,col_factors])
```

Veiem com s'han factoritzat correctament.

Addicionalment, podem discretitzar variables continues que ens puguin ser d'utilitat, com per exemple la variable `Age`.

Per discretitzar aquesta variable farem servir la funció `discretize` de la llibreria `arules`. Aquesta funció permet fer la discretització amb quatre mètodes: intervals de mateixa amplitud, intervals amb la mateixa freqüència (nombre de instàncies), fent *clustering* amb k-means i amb intervals fixats prèviament. Nosaltres hem optat pel mètode de *clustering* amb una $k=5$, ja que tenim edats de 2 mesos fins a 80 anys. Anem a veure si amb $k=5$ es creen uns intervals representatius (respecte a grups d'edat: adolescent, jove, adult, etc.).

```{r}
table(discretize(titanic$Age, "cluster", breaks = 5 ))
```

Els intervals semblen ser bastant representatius, els intervals per ordre es podrien identificar com a: nen, jove, adult, adult-gran, gran.

Visualitzem com es veuria aquesta discretització a la distribució de la variable `Age`.

```{r, fig.width=5,fig.height=3}
hist(titanic$Age, main="Distribució de l'edat dels passatgers",xlab="Edat",
     ylab="Quantitat",col = "gold")
abline(v=discretize(titanic$Age, method="cluster", onlycuts=TRUE, breaks = 5),col="red")
```

```{r}
titanic$segment_age <- discretize(titanic$Age, "cluster", breaks = 5, 
                                  labels = c("nen","jove","adult","adult-gran","gran") )
```

## Selecció de dades

Pensem que tots els camps poden ser necessaris per això els valorarem tots. Però som conscients que hi ha camps que té pinta que siguin més significants que altres. Per exemple, el camp `Name`, no té pinta que tingui relevància, però podem extreure el títol del passatger. Per tant, substituïrem la columna `Name`, per un nou camp calculat.

Podem extreure noves variables de columnes existents (com hem fet prèviament amb `hasCabin`). Com acabem de mencionar se'ns ofereix informació sobre el nom de cada passatger, la qual cosa no sembla rellevant, però d'aquí podem extreure el títol de cada individu (Mr, Mrs, etc.). Procedim a extreure'l i esborrar el camp `Name`.

```{r}
titanic$title <- gsub('(.*, )|(\\..*)', '', titanic$Name)
table(titanic$title)
titanic$Name <- NULL
```

Veiem que els títols més repetits són *Miss*, *Mrs*, *Mr* i *Master*. Però addicionalment tenim altres valors com: *Ms* que és el mateix que *Miss*, *Dona* i *Lady* que són sinònims de *Mrs*, i *Don* i *Sir* que són sinònims de *Mr*. Aquests sinònims són títols nobiliaris, entre altres, i com només ens interessa mostrar la creació de nous atributs a partir d'existents i no fer un anàlisi exhaustiu sobre aquest aspecte ens quedarem amb els títols de *Mrs*, *Miss*, *Mr* i *Master*. La resta de títols els catalogarem com `Special`.

```{r}
titanic$title[titanic$title == "Dona"] <- "Mrs"
titanic$title[titanic$title == "Lady"] <- "Mrs"
titanic$title[titanic$title == "Ms"] <- "Miss"
titanic$title[titanic$title == "Don"] <- "Mr"
titanic$title[titanic$title == "Sir"] <- "Mr"

residual <- c("Capt", "Col", "Dr", "Jonkheer", "Major", "Mile", "Mme", "Rev",
              "the Countess", "Mlle")
titanic$title[titanic$title %in% residual] <- "Special"
titanic$title <- as.factor(titanic$title)
summary(titanic$title)
```

Un altre atribut que podem extreure és la mida de la família (contant-se el propi passatger) que viatja conjuntament al Titanic

```{r}
titanic$FamilySize <- titanic$SibSp + titanic$Parch +1
summary(titanic$FamilySize)
```

Veiem com la majora viatgen sols (la mida de la família és 1), 

## Valors extrem

Ara anem a tractar els valors extrem (*outliers*). 

```{r}
# Agafem les variables numèriques
numCols <- c("Age", "SibSp", "Parch","Fare")
sapply(colnames(titanic[,numCols]), function(x) boxplot.stats(titanic[,x])$out)
```

Com podem veure, cap valor extrem sembla ser erroni ni molt allunyat del conjunt de valors. Per exemple, la columna `Fare`, té algun valor allunyat (512.3292) que es pot correspondre per un bitllet de primera classe [[Ref](https://www.cruisemummy.co.uk/titanic-ticket-prices/)].  Per tant, no cal fer cap tractament d'aquests *outliers*.

## Clean data

Passem a guardar les dades netejades:

```{r}
write.csv(titanic, "data/titanic_clean.csv", row.names = F)
```

# Visualització de les dades

Procedim doncs a visualitzar les distribucions d'algunes de les columnes que ens poden explicar millor el factor clau per la supervivència en l'enfonsament del Titànic. Aquestes són: `Pclass`, `Sex`, `segment_age`, `Sibsp`, `Embarked` i `FamilySize`. Això no significa que sigui les úniques variables que farem servir.

```{r, fig.width=4,fig.height=2.5}
train_data <- titanic[titanic$data == "train",]
ggplot(data= train_data,aes(x=Sex,fill=Survived)) + geom_bar() +  ggtitle("Sexe")

ggplot(data = train_data,aes(x=Embarked,fill=Survived)) +
  geom_bar(position="fill") +  ylab("Freq.") + ggtitle("Port d'embarcació")

ggplot(data = train_data,aes(x=Embarked,fill=Survived))+
  geom_bar(position="fill") +  facet_wrap(~Pclass) +  ggtitle("Port d'embarcació + Classe")

ggplot(data = train_data,aes(x=Pclass,fill=Survived))+  geom_bar(position="fill") +
  facet_wrap(~Sex) +  ggtitle("Classe + Sexe")

ggplot(data = train_data,aes(x=SibSp,fill=Survived)) +
  geom_bar() +  ggtitle("Nombre de germans/esposes")

ggplot(data = train_data,aes(x=Parch,fill=Survived)) +
  geom_bar() +  ggtitle("Nombre de fills/pares")

ggplot(data = train_data, aes(x=FamilySize,fill=Survived)) +
  geom_histogram(binwidth =1,position="fill", color = "white") +
  ylab("Freqüència")+  ggtitle("mida de la família")

ggplot(data= train_data,aes(x=segment_age,fill=Survived)) +  geom_bar() +  ggtitle("Edat")
```

A simple vista podem deduir que aquestes variables seran bones candidates a ser variables explicatives per al nostre model, ja que s'observen diferències significatives entre les categories de la variable respecte si van sobreviure o no.

Anem a veure un exemple per a avaluar la relació existent entre una variable explicativa i la nostra variable target. Prenem la variable `Sex`. Utilitzarem el test de Fisher per a avaluar si existeix associació entre la variable sexe i el fet de sobreviure. Plantegem les hipòtesis següents:

$H_0$: Les variables són independents, ie, els valors de sexe no influeixen en els valors que pren la variable `Survived`

$H_1$: Les variables són dependents, ie, els valors que pren la variable sexe tenen relació amb els valors que pren la variable `Survived`



```{r}
tt <- table(titanic$Survived[titanic$data=="train"], titanic$Sex[titanic$data=="train"],
            dnn = c("Sobreviu", "Sexe"))
fisher.test(x = tt, alternative = "two.sided")
```

Observem que el p-valor inferior a 0.05 ens permet rebutjar la hipòtesi nul·la i dir que tenim relació entre la variable sexe i el fet de sobreviure. Anem a avaluar la contundència d'aquesta relació analitzant la força d'associació: 

```{r}
assocstats(x = tt)
```

Un coeficient V de Cramer a partir de 0.5 es considera (per convenció) una força d'associació gran (tamany de l'efecte).

# Anàlisi de les dades

## Selecció dels grups de dades

Anem a comprovar la normalitat i homogeneïtat de la variància.

### Normalitat

```{r, fig.width=4,fig.height=3}
qqPlot(titanic$Age)
shapiro.test(titanic$Age) 

qqPlot(titanic$SibSp)
shapiro.test(titanic$SibSp) 

qqPlot(titanic$Parch) 
shapiro.test(titanic$Parch) 

qqPlot(titanic$Fare) 
shapiro.test(titanic$Fare) 
```

Com veiem cap nivell de significança és major que 0.05, ni les dades estan dins de l'interval de confiança. Per tant, cap d'aquestes variables presenta normalitat.

### Homogeneitat de la variància

Com sabem, molts testos estadístics assumeixen la homogeneitat de la variància per a dur a terme contrastos d'hipòtesis. Això és, que en incrementar el valor una variable explicativa, la nostra variable dependent manté la variància constant. En el nostre cas però, estem davant d'una variable target categòrica amb dues classes (sobreviu, no sobreviu) i doncs, no té massa rellevància aquest estudi.

# Classificació

## GLM

Anem a construir un model de regressió logística per predir si un passatger sobreviu o no. Construirem un model lineal generalitzat (GLM) amb la familia binomial.

```{r}
model.glm <- glm(Survived ~ Sex + Pclass + Age + Fare + 
                   Embarked + segment_age + title + hasCabin + FamilySize,
                 data = titanic[titanic$data == "train",],
                 family = binomial)
summary(model.glm)
```

Veiem que les variables que expliquen la major part del factor de supervivència en el nostre model són: `Pclass`, `title`, `FamilySize` i `hasCabin`. 

Anem a predir la supervivència dels passatgers

```{r}
titanic$pred <- predict(model.glm, titanic)
```

Per tal de veure com de bé s'ajusta aquest model es pot utilitzar la corba ROC, que representa la relació entre la ratio de vertaders positius (TPR) i de falsos positius (FPR):

```{r, fig.width=3,fig.height=3}
roc <- roc(titanic$Survived, titanic$pred)
plot(roc)
```

Veiem que es la corba es troba molt per sobre de la línia diagonal i doncs deduim que tenim un bon classificador. El classificador òptim és aquell on la corba creix en perpendicular a l'eix d'abcisses fins a y=1 i després es manté en l'ordenada 1 fins a x=1. 

Amb les probabilitats trobades, assignem el valor corresponent a la variable target.

```{r}
titanic$predSurvived <- ifelse(titanic$pred < 0.5, 0, 1)
```

Obtenim així la predicció del conjunt de test:

```{r}
output <- titanic[titanic$data == "test", c("PassengerId", "predSurvived")]
colnames(output) <- c("PassengerId", "Survived")
```


## Arbres de decisió

Els arbres de decisió són un dels models supervisats de classificació que s’usen més en problemes de mineria de dades. La raó principal és perquè tenen una alta capacitat explicativa i perquè és molt fàcil interpretar el model que se n’obté.

Així doncs és ideal per aplicar-lo en el nostre cas. Utilitzarem la funció `c5.0` de la llibreria `c50`.

Selecciones les columnes d'interés.
```{r}
interest_cols = c("Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Embarked", "title",
                  "segment_age", "FamilySize", "hasCabin")
```

Amb aquestes columnes crearem el model i l'entrenarem. Amb la funció `summary` i l'atribut `rules=TRUE` podrem analitzar a fons l'arbre de decisió creat.

```{r}
model <- C50::C5.0(titanic[titanic$data == "train",interest_cols],
                   titanic$Survived[titanic$data == "train"],
                   rules=TRUE )
summary(model)
```

Primer de tot analitzem la taxa d'error: `Errors` mostra el número i percentatge de casos mal classificats en el subconjunt d’entrenament. L’arbre obtingut classifica erròniament 110 dels 891 casos donats, una taxa d’error del 12,3%.

En total tenim 19 regles. Les regles estan numerades i estan acompanyades de dos valors `(n, lift x)` on $n$ a vegades està de la forma $n/m$. $n$ és el nombre de casos d'entrenament tractats per la regla i $m$, si hi és, indica quants no pertanyen a la classe que prediu la regla. La precisió de la regla és estimada pel ratio de Laplace $(n-m+1)/(n+2)$. I `lift x` és el resultat de dividir la precisió estimada per la freqüència relativa de la classe predita en el conjunt d'entrenament. També podem veure les condicions que s'han de satisfer, la classe que prediu la regla i la confidència amb la que la regla prediu la classe.

Com a exemple analitzarem la primera regla a fons. Aquesta regla tracta 41 observacions i prediu amb una confidència del 9,7% que 38 dels 41 passatgers que eren homes i van embarcar al port de Queenston no van sobreviure (`class 0`).

Si ens hi fixem en varies regles veiem com un dels trets més distintius és el sexe. Les regles que classifiquen passatgers com a no supervivents, com per exemple la regla 1, 3, 4 o 6, tenen un distintiu masculí, ja sigui pel títol o pel sexe mateix. I les que classifiquen passatgers com a supervivents solen valorar el fet que el passatger sigui una dona, per exemple les regles 7, 10, 11, 12 o 15.

Anem a veure la precisió de l'arbre a partir de la matriu de contingència.
```{r}
titanic$dtSurvived <- NA
predicted_model <- predict( model,
                            titanic[titanic$data=='test', interest_cols],
                            type="class" )
titanic[titanic$data=="test",]$dtSurvived <- predicted_model
head(titanic[titanic$data=="test",]$dtSurvived, 10)
```

Hem predit la supervivència dels passatgers de les dades d'avaluació. Podem extreure el percentatge de passatgers que van sobreviure amb:

```{r}
surv <- titanic[titanic$data=="test",]$dtSurvived

(length(surv[surv==2]))/(length(surv))
```

Un 34,69% dels passatgers no van sobreviure.


##  Random Forest

Un altre algorisme que funciona en base als arbres de decisió és el *random forest*. Aquest genera una multitud d'arbres de decisió i, en el cas dels projectes de classificació, selecciona la classe que més arbres de decisió han seleccionat.

```{r}
interest_cols = c("Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Embarked", "title",
                  "segment_age", "FamilySize", "hasCabin")

classifier <- randomForest(x = titanic[titanic$data == "train",interest_cols],
                           y = titanic$Survived[titanic$data == "train"],
                           ntree = 500, random_state = 0)

titanic$rfPred <- NA
pred <- predict(classifier, 
                newdata = titanic[titanic$data == "test", interest_cols])
titanic[titanic$data == "test",]$rfPred <- pred
```

Amb la predicció usant el random forest tenim una taxa de supervivència en els passatgers del conjunt de dades d'avaluació del:

```{r}
surv <- titanic[titanic$data == "test",]$rfPred
(length(surv[surv==1]))/(length(surv))
```

La taxa de supervivència és del 35,41%, hi ha una diferència de 0,72 punts amb la predicció de l'arbre de decisió.


Hem vist diferents mètodes per fer la classificació, i si haguéssim d'escollir un mètode per respondre a la pregunta de quins passatgers sobreviuen en el conjunt de dades d'avaluació, escolliríem el mètode random forest, degut al seu potencial i al fet de que utilitza 500 arbres de decisió per fer la classificació, essent així més fiable que no pas un sol arbre de decisió.

Per tant adjudiquem aquests valors al camp `Survived`:

```{r}
titanic[titanic$data == "test",]$Survived <- as.factor(
  titanic[titanic$data == "test",]$rfPred-1) # els valors estan en 1 i 2, enlloc de 0 i 1
```

# Conclusions

Hem vist com atacar el problema dels valors mancants amb les dades amb dues tècniques diferents (utitzant la mediana i amb el mètode KNN). A més, hem analitzat els valors extrems i dut a terme un anàlisi de la distribució de les dades i la relació que tenen amb la nostra variable target (`Survived`). Aquest anàlisi l'hem realitzat tant visualment com amb una proba estadística. 

Per altra banda, hem pogut veure com poder extreure informació de dades que inicialment no era possible tractar. Per exemple, el cas del nom del passatger podria ser fàcilment ignorat, però hem constatat que contenia informació rellevant (títol o forma de tractament) i significativa per al nostre model. 

Hem creat 3 models classificadors per a predir si un passatger sobreviu o no. En primer lloc hem realitzat un model de regressió logística, seguit d'un arbre de decisió i acabant amb un model random forest.

# Contribucions

Aquest estudi ha estat realitzat conjuntament per l'Adem Ait (AA) i el Dani Ponce (DP):

+ **Investigació prèvia**: AA, DP
+ **Redacció de les respostes**: AA, DP
+ **Desenvolupament codi**: AA, DP


